{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('./input/train.csv') \n",
    "test_data=pd.read_csv('./input/test.csv')\n",
    "\n",
    "target = train_data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"Embarked\", y=\"Survived\", hue=\"Sex\", data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of train dataset:-',train_data.shape)\n",
    "print('Shape of test dataset:-' ,test_data.shape)\n",
    "\n",
    "#Info about datatype and statistical model\n",
    "\n",
    "print('\\n')\n",
    "print(train_data.info())\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining both train and test dataset\n",
    "total=pd.concat([train_data.drop('Survived',axis=1),test_data])\n",
    "target=train_data['Survived']\n",
    "\n",
    "total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value_percentage(df):\n",
    "    total = df.isnull().sum().sort_values(ascending = False)\n",
    "    percent = round(total/len(df)*100,2)\n",
    "    print(pd.concat([total, percent], axis=1, keys=['Total','Percent']))\n",
    "\n",
    "missing_value_percentage(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(total.drop('PassengerId',axis=1).corr(),annot=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_percent_value(df, feature):\n",
    "    percent = pd.DataFrame(round(df.loc[:,feature].value_counts(dropna=False, normalize=True)*100,2))\n",
    "    total = pd.DataFrame(df.loc[:,feature].value_counts(dropna=False))\n",
    "\n",
    "    total.columns = [\"Total\"]\n",
    "    percent.columns = ['Percent']\n",
    "    return pd.concat([total, percent], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_percent_value(total, 'Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.Embarked.fillna(\"S\", inplace=True)\n",
    "total['Age'] = total.Age.fillna(total.Age.median())\n",
    "total['Fare'] = total.Fare.fillna(total.Fare.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "total['Sex'] = encoder.fit_transform(total['Sex'])\n",
    "total['Embarked'] = encoder.fit_transform(total['Embarked'])\n",
    "total=pd.get_dummies(total, columns = ['Pclass','Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['Fare_1_S']=total['Embarked_2']*total['Pclass_1']*total['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_ages(df):\n",
    "    df['Age_cat'] = pd.qcut(total['Age'],q=[0, .16, .33, .49, .66, .83, 1], labels=False, precision=1)\n",
    "    return df\n",
    "\n",
    "# def simplify_cabins(df):\n",
    "#     df.Cabin = df.Cabin.fillna('N')\n",
    "#     df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
    "#     return df\n",
    "\n",
    "def format_name(df):\n",
    "#     #Extracting Title from name\n",
    "    df['Title'] =df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title'] =df['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    df['Title'] =df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] =df['Title'].replace('Ms', 'Miss')\n",
    "    df['Title'] =df['Title'].replace('Mme', 'Mrs')\n",
    "    #Mapping titles to numerical data\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 2, \"Master\": 3, \"Rare\": 4}\n",
    "    df['Title'] =df['Title'].map(title_mapping)\n",
    "    df['Title'] =df['Title'].fillna(0)\n",
    "#     df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n",
    "#     df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n",
    "    return df\n",
    "\n",
    "def simplify_family(df):\n",
    "    #Family group\n",
    "    df['FamilySize'] =df['SibSp'] + df['Parch'] + 1\n",
    "    df['FamilySize_cat'] =df['FamilySize'].map(lambda x: 1 if x == 1 else (2 if 5 > x >= 2 else (3 if 8 > x >= 5 else 4 )))\n",
    "    return df\n",
    "\n",
    "def drop_features(df):\n",
    "    return df.drop(['Cabin', 'Ticket', 'Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare_category(fr): \n",
    "    if fr <= 7.91:\n",
    "        return 1\n",
    "    elif fr <= 14.454 and fr > 7.91:\n",
    "        return 2\n",
    "    elif fr <= 31 and fr > 14.454:\n",
    "        return 3\n",
    "    return 4\n",
    "total['Fare_cat'] =total['Fare'].apply(fare_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = simplify_ages(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = simplify_family(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = format_name(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = drop_features(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy variable\n",
    "total=pd.get_dummies(total,columns=['SibSp','Parch','Title','FamilySize','Fare_cat','FamilySize_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['Age']=total['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = total[:len(train_data)]\n",
    "test_data = total[len(test_data):]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, target, test_size = 0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODELS IMPORT\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\"KNN\": KNeighborsClassifier(),\n",
    "          \"Logistic Regression\": LogisticRegression(max_iter=10000), \n",
    "          \"Random Forest\": RandomForestClassifier(),\n",
    "          \"SVC\" : SVC(probability=True),\n",
    "          \"DecisionTreeClassifier\" : DecisionTreeClassifier(),\n",
    "          \"AdaBoostClassifier\" : AdaBoostClassifier(),\n",
    "          \"GradientBoostingClassifier\" : GradientBoostingClassifier(),\n",
    "          \"GaussianNB\" : GaussianNB(),\n",
    "          \"LinearDiscriminantAnalysis\" : LinearDiscriminantAnalysis(),\n",
    "          \"QuadraticDiscriminantAnalysis\" : QuadraticDiscriminantAnalysis()}\n",
    "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Random seed for reproducible results\n",
    "    np.random.seed(42)\n",
    "    # Make a list to keep model scores\n",
    "    model_scores = {}\n",
    "    # Loop through models\n",
    "    for name, model in models.items():\n",
    "        # Fit the model to the data\n",
    "        model.fit(X_train, y_train)\n",
    "        # Predicting target values\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Evaluate the model and append its score to model_scores\n",
    "        #model_scores[name] = model.score(X_test, y_test)\n",
    "        model_scores[name] = roc_auc_score(y_pred, y_test)\n",
    "    return model_scores\n",
    "model_scores = fit_and_score(models=models,\n",
    "                             X_train=X_train,\n",
    "                             X_test=X_test,\n",
    "                             y_train=y_train,\n",
    "                             y_test=y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_random_forest = LogisticRegression(max_iter=10000)\n",
    "clf_random_forest.fit(train_data, target)\n",
    "\n",
    "prediction = clf_random_forest.predict(test_data)\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': prediction})\n",
    "output.to_csv('submission_v6.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier(colsample_bylevel= 0.9,\n",
    "                    colsample_bytree = 0.8, \n",
    "                    gamma=0.99,\n",
    "                    max_depth= 5,\n",
    "                    min_child_weight= 1,\n",
    "                    n_estimators= 10,\n",
    "                    nthread= 4,\n",
    "                    random_state= 2,\n",
    "                    silent= True)\n",
    "classifier.fit(X_train,y_train)\n",
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = classifier.predict(test_data)\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId,'Survived': prediction})\n",
    "output.to_csv('submission_v7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('tf-gpu-v0.1': conda)",
   "language": "python",
   "name": "python361064bittfgpuv01conda4ce7eb32e2434341ad881895c717db38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
